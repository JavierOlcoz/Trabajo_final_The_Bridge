{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.3 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "e922dd073470bdcc017ae3abd31d6491d6ed7bf31c1d559806e5511bfea88b81"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# The Simpsons family Classification"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### By Javier Olcoz Macayo\n",
    "### @JavierOlcoz\n",
    "### mrjolma@gmail.com"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### This notebook will create, fit and save the model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "from utils import folders_tb as ft\n",
    "from utils import models_tb as mt\n",
    "#from utils import mining_data_tb as mdt\n",
    "#from utils import visualization_tb as vis\n",
    "#from utils import apis_tb as ap\n",
    "\n",
    "\n",
    "# Create objects\n",
    "variable_creator = ft.Folders()\n",
    "variable_model = mt.Modelo()\n",
    "#variable_miner = mdt.Miner()\n",
    "#variable_visual = vis.Visualization()\n",
    "#variable_apis = ap.Apis()"
   ]
  },
  {
   "source": [
    "## Create the train set with an image generator"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_datagen = variable_creator.training_datagen(rescale=1./255,featurewise_center=False, samplewise_center=False, featurewise_std_normalization=False, samplewise_std_normalization=False, rotation_range=0, width_shift_range=0.1, height_shift_range=0.1, horizontal_flip=True,vertical_flip=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Found 7274 images belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "IMG_SIZE = 224\n",
    "\n",
    "TRAINING_DIR = '../data/familia_simpsons_train/'\n",
    "\n",
    "train_generator = variable_creator.train_generator(training_datagen, TRAINING_DIR,target_size=(IMG_SIZE,IMG_SIZE), class_mode='categorical', batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "inv_class_map = variable_creator.class_indices(train_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{0: 'abraham_grampa_simpson',\n",
       " 1: 'bart_simpson',\n",
       " 2: 'homer_simpson',\n",
       " 3: 'lisa_simpson',\n",
       " 4: 'maggie_simpson',\n",
       " 5: 'marge_simpson'}"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "inv_class_map"
   ]
  },
  {
   "source": [
    "## Create the test set "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "For testing data , found 248 files\n",
      "X_test shape : (248, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "X_test = variable_creator.test_images('../data/familia_simpsons_test/', 224)"
   ]
  },
  {
   "source": [
    "## Create, fit and save the model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### I will use the pre-trained model VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg16_base = variable_model.vgg16_base_1(include_top=False,\n",
    "                   input_tensor=None, input_shape=(IMG_SIZE, IMG_SIZE, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Adding new layers...\nNew layers added!\n"
     ]
    }
   ],
   "source": [
    "vgg16_model = variable_model.vgg16_model_1(vgg16_base, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "saving_path = '../models/VGG16_15_epochs_model.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/15\n",
      "  1/114 [..............................] - ETA: 28:58 - loss: 2.2320 - accuracy: 0.0625"
     ]
    }
   ],
   "source": [
    "history = variable_model.compile_and_fit(vgg16_model, train_generator, 15, saving_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}