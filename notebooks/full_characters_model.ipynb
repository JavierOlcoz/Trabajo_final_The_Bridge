{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.3 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "e922dd073470bdcc017ae3abd31d6491d6ed7bf31c1d559806e5511bfea88b81"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd \n",
    "import os\n",
    "import tensorflow.keras as keras\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.layers import Dense,GlobalAveragePooling2D, MaxPooling2D, Conv2D, Flatten, Dropout\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.optimizers import RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Found 20933 images belonging to 42 classes.\n"
     ]
    }
   ],
   "source": [
    "IMG_SIZE = 224\n",
    "\n",
    "TRAINING_DIR = '../data/simpsons_dataset/'\n",
    "\n",
    "training_datagen = ImageDataGenerator(rescale=1./255, featurewise_center=False, # set input mean to 0 over the dataset\n",
    " samplewise_center=False, # set each sample mean to 0\n",
    " featurewise_std_normalization=False, # divide inputs by std \n",
    " samplewise_std_normalization=False, # divide each input by its std\n",
    " rotation_range=0, # randomly rotate images in the range \n",
    " width_shift_range=0.1, # randomly shift images horizontally \n",
    " height_shift_range=0.1, # randomly shift images vertically \n",
    " horizontal_flip=True, # randomly flip images\n",
    " vertical_flip=False)\n",
    "\n",
    "train_generator = training_datagen.flow_from_directory(TRAINING_DIR,target_size=(IMG_SIZE,IMG_SIZE), class_mode='categorical', batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{0: 'abraham_grampa_simpson',\n",
       " 1: 'agnes_skinner',\n",
       " 2: 'apu_nahasapeemapetilon',\n",
       " 3: 'barney_gumble',\n",
       " 4: 'bart_simpson',\n",
       " 5: 'carl_carlson',\n",
       " 6: 'charles_montgomery_burns',\n",
       " 7: 'chief_wiggum',\n",
       " 8: 'cletus_spuckler',\n",
       " 9: 'comic_book_guy',\n",
       " 10: 'disco_stu',\n",
       " 11: 'edna_krabappel',\n",
       " 12: 'fat_tony',\n",
       " 13: 'gil',\n",
       " 14: 'groundskeeper_willie',\n",
       " 15: 'homer_simpson',\n",
       " 16: 'kent_brockman',\n",
       " 17: 'krusty_the_clown',\n",
       " 18: 'lenny_leonard',\n",
       " 19: 'lionel_hutz',\n",
       " 20: 'lisa_simpson',\n",
       " 21: 'maggie_simpson',\n",
       " 22: 'marge_simpson',\n",
       " 23: 'martin_prince',\n",
       " 24: 'mayor_quimby',\n",
       " 25: 'milhouse_van_houten',\n",
       " 26: 'miss_hoover',\n",
       " 27: 'moe_szyslak',\n",
       " 28: 'ned_flanders',\n",
       " 29: 'nelson_muntz',\n",
       " 30: 'otto_mann',\n",
       " 31: 'patty_bouvier',\n",
       " 32: 'principal_skinner',\n",
       " 33: 'professor_john_frink',\n",
       " 34: 'rainier_wolfcastle',\n",
       " 35: 'ralph_wiggum',\n",
       " 36: 'selma_bouvier',\n",
       " 37: 'sideshow_bob',\n",
       " 38: 'sideshow_mel',\n",
       " 39: 'snake_jailbird',\n",
       " 40: 'troy_mcclure',\n",
       " 41: 'waylon_smithers'}"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "class_map = train_generator.class_indices\n",
    "inv_class_map = {v: k for k, v in class_map.items()}\n",
    "inv_class_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv2d (Conv2D)              (None, 224, 224, 32)      896       \n_________________________________________________________________\nmax_pooling2d (MaxPooling2D) (None, 112, 112, 32)      0         \n_________________________________________________________________\nconv2d_1 (Conv2D)            (None, 112, 112, 64)      18496     \n_________________________________________________________________\nmax_pooling2d_1 (MaxPooling2 (None, 56, 56, 64)        0         \n_________________________________________________________________\nconv2d_2 (Conv2D)            (None, 56, 56, 128)       73856     \n_________________________________________________________________\nmax_pooling2d_2 (MaxPooling2 (None, 28, 28, 128)       0         \n_________________________________________________________________\nconv2d_3 (Conv2D)            (None, 28, 28, 256)       295168    \n_________________________________________________________________\nmax_pooling2d_3 (MaxPooling2 (None, 14, 14, 256)       0         \n_________________________________________________________________\nconv2d_4 (Conv2D)            (None, 14, 14, 512)       1180160   \n_________________________________________________________________\nmax_pooling2d_4 (MaxPooling2 (None, 7, 7, 512)         0         \n_________________________________________________________________\nconv2d_5 (Conv2D)            (None, 7, 7, 1024)        4719616   \n_________________________________________________________________\nmax_pooling2d_5 (MaxPooling2 (None, 3, 3, 1024)        0         \n_________________________________________________________________\nflatten (Flatten)            (None, 9216)              0         \n_________________________________________________________________\ndense (Dense)                (None, 128)               1179776   \n_________________________________________________________________\ndropout (Dropout)            (None, 128)               0         \n_________________________________________________________________\ndense_1 (Dense)              (None, 42)                5418      \n=================================================================\nTotal params: 7,473,386\nTrainable params: 7,473,386\nNon-trainable params: 0\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(filters=32, kernel_size=(3,3), input_shape=(IMG_SIZE, IMG_SIZE, 3), activation=\"relu\", padding=\"same\"))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(filters=64, kernel_size=(3,3), activation=\"relu\", padding=\"same\"))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(filters=128, kernel_size=(3,3), activation=\"relu\", padding=\"same\"))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(filters=256, kernel_size=(3,3), activation=\"relu\", padding=\"same\"))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(filters=512, kernel_size=(3,3), activation=\"relu\", padding=\"same\"))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(filters=1024, kernel_size=(3,3), activation=\"relu\", padding=\"same\"))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "                                  \n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation=\"relu\"))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(42, activation=\"softmax\"))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer=RMSprop(), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/15\n",
      "328/328 [==============================] - 1871s 6s/step - loss: 4.1088 - accuracy: 0.0976\n",
      "Epoch 2/15\n",
      "328/328 [==============================] - 1682s 5s/step - loss: 2.2264 - accuracy: 0.3983\n",
      "Epoch 3/15\n",
      "328/328 [==============================] - 1695s 5s/step - loss: 1.3545 - accuracy: 0.6394\n",
      "Epoch 4/15\n",
      "328/328 [==============================] - 1636s 5s/step - loss: 0.9141 - accuracy: 0.7613\n",
      "Epoch 5/15\n",
      "328/328 [==============================] - 1635s 5s/step - loss: 0.7156 - accuracy: 0.8134\n",
      "Epoch 6/15\n",
      "328/328 [==============================] - 1634s 5s/step - loss: 0.6331 - accuracy: 0.8396\n",
      "Epoch 7/15\n",
      "328/328 [==============================] - 1632s 5s/step - loss: 0.5753 - accuracy: 0.8522\n",
      "Epoch 8/15\n",
      "328/328 [==============================] - 1630s 5s/step - loss: 0.5312 - accuracy: 0.8677\n",
      "Epoch 9/15\n",
      "328/328 [==============================] - 1632s 5s/step - loss: 0.5151 - accuracy: 0.8772\n",
      "Epoch 10/15\n",
      "328/328 [==============================] - 1631s 5s/step - loss: 0.5034 - accuracy: 0.8784\n",
      "Epoch 11/15\n",
      "328/328 [==============================] - 1628s 5s/step - loss: 0.5090 - accuracy: 0.8844\n",
      "Epoch 12/15\n",
      "328/328 [==============================] - 1642s 5s/step - loss: 0.5610 - accuracy: 0.8726\n",
      "Epoch 13/15\n",
      "328/328 [==============================] - 1633s 5s/step - loss: 0.5556 - accuracy: 0.8734\n",
      "Epoch 14/15\n",
      "328/328 [==============================] - 1629s 5s/step - loss: 0.5870 - accuracy: 0.8702\n",
      "Epoch 15/15\n",
      "328/328 [==============================] - 1627s 5s/step - loss: 0.6532 - accuracy: 0.8654\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 15\n",
    "\n",
    "history = model.fit(train_generator, batch_size=64, epochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.save('simpsons_definitive_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}